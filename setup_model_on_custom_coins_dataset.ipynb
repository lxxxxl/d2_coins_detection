{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2 custom dataset setup.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB2sajyR5HMO",
        "colab_type": "text"
      },
      "source": [
        "#Install Detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td-HCvIT5Mw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies: (use cu100 because colab is on CUDA 10.0)\n",
        "!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "torch.__version__\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saX7e-9X73Bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QqWTe9D5TGc",
        "colab_type": "text"
      },
      "source": [
        "# Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cls4AeN5Nd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6wKcYY45c7t",
        "colab_type": "text"
      },
      "source": [
        "# Prepare custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OzOrsqLtY70",
        "colab_type": "text"
      },
      "source": [
        "To prepare custom dataset [coco-annotator](https://github.com/jsbroks/coco-annotator) can be used.  \n",
        "Docker based setup instructions can be found [here](https://github.com/jsbroks/coco-annotator/wiki/Getting-Started#installing-with-docker).  \n",
        "If you prefer desktop app, you can use [labelme](https://github.com/wkentaro/labelme)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Roy0nKpE4oW2",
        "colab_type": "text"
      },
      "source": [
        "Import dataset from gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g_FbpT84R2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VutfVm09y4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGokLbOy4uOZ",
        "colab_type": "text"
      },
      "source": [
        "Check if dataset is available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB-Cgbn14wER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls '/content/gdrive/My Drive/D2CustomDataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh9x0nWS5pPM",
        "colab_type": "text"
      },
      "source": [
        "Register the coin dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n",
        "Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format.  \n",
        "Annotations were generated with [labelme](https://github.com/wkentaro/labelme), so convert them to detectron2 format.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmdwgHMo44Ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "def label_to_category_id(label):\n",
        "\t\"\"\"labelme generates text labels, but detectron2 wants numerical category ids\"\"\"\n",
        "\tlabels = {\n",
        "\t\t'coin'\t: 0\n",
        "\t}\n",
        "\t\n",
        "\tif label not in labels:\n",
        "\t\treturn -1\n",
        "\n",
        "\treturn labels[label]\n",
        "\t\n",
        "\t\n",
        "def get_coin_dicts(img_dir):\n",
        "\tdataset_dicts = []  \n",
        "\tidx = 0\n",
        "\tfor file in os.listdir(img_dir):\n",
        "\t\tif not file.endswith('.json'):\n",
        "\t\t\tcontinue\n",
        "\t\t\n",
        "\t\tjson_file = os.path.join(img_dir, file)\n",
        "\t\twith open(json_file) as f:\n",
        "\t\t\timg_ann = json.load(f)\n",
        "\t\t\n",
        "\t\trecord = {}\n",
        "\t\t\n",
        "\t\tfilename = os.path.join(img_dir, img_ann['imagePath'])\n",
        "\t\t\t\n",
        "\t\trecord['file_name'] = filename\n",
        "\t\trecord['image_id'] = idx\n",
        "\t\trecord['height'] = img_ann['imageHeight']\n",
        "\t\trecord['width'] = img_ann['imageWidth']\n",
        "\t\t\n",
        "\t\tannos = img_ann['shapes']\n",
        "\t\tobjs = []\n",
        "\t\tfor anno in annos:\n",
        "\t\t\tassert anno['points']\n",
        "\t\t\tif anno['shape_type'] == 'polygon':\n",
        "\t\t\t\tpoly = []\n",
        "\t\t\t\tbbox = [np.inf,np.inf,-np.inf,-np.inf]\t# x_min, y_min, x_max, y_max\n",
        "\t\t\t\tfor x, y in anno['points']:\n",
        "\t\t\t\t\tpoly.append(x+0.5)\n",
        "\t\t\t\t\tpoly.append(y+0.5)\n",
        "\t\t\t\t\t# set bounding box coords\n",
        "\t\t\t\t\tif x < bbox[0]: bbox[0] = x\n",
        "\t\t\t\t\tif x > bbox[2]: bbox[2] = x\n",
        "\t\t\t\t\tif y < bbox[1]: bbox[1] = y\n",
        "\t\t\t\t\tif y > bbox[3]: bbox[3] = y\n",
        "\t\t\t\t\tobj = {\n",
        "\t\t\t\t\t\t'bbox': bbox,\n",
        "\t\t\t\t\t\t'bbox_mode': BoxMode.XYXY_ABS,\n",
        "\t\t\t\t\t\t'segmentation': [poly],\n",
        "\t\t\t\t\t\t'category_id': label_to_category_id(anno['label']),\n",
        "\t\t\t\t\t\t'iscrowd': 0\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t\tobjs.append(obj)\n",
        "\t\trecord['annotations'] = objs\n",
        "\t\tdataset_dicts.append(record)\n",
        "\t\tidx += 1\n",
        "\t\n",
        "\treturn dataset_dicts\n",
        "\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "gdrive_dir = '/content/gdrive/My Drive/D2CustomDataset/'\n",
        "for d in ['train', 'val']:\n",
        "    DatasetCatalog.register(\"coin_\" + d, lambda d=d: get_coin_dicts(gdrive_dir + d))\n",
        "    MetadataCatalog.get(\"coin_\" + d).set(thing_classes=[\"coin\"])\n",
        "coin_metadata = MetadataCatalog.get(\"coin_train\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNElqMyl5yKb",
        "colab_type": "text"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-wPEOk55y8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dicts = get_coin_dicts(gdrive_dir + 'train')\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d['file_name'])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=coin_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNh2Uwtk5-Ps",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bxzTl9O6A7H",
        "colab_type": "text"
      },
      "source": [
        "Now, let's fine-tune a coco-pretrained R50-FPN Mask R-CNN model on custom dataset.  \n",
        "Training on Colab's P100 GPU is usually 3 times faster than on K80 GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRlu33rQ6FV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file('COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml'))\n",
        "cfg.DATASETS.TRAIN = ('coin_train',)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml')  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 500    # 500 iterations seems good enough for my dataset, can be changed empirically\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # this param should be changed empirically too\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (coin)\n",
        "cfg.OUTPUT_DIR = gdrive_dir\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQrz7zRk6LQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUmYB6MG6TWW",
        "colab_type": "text"
      },
      "source": [
        "# Test model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfeA8eKu6VxP",
        "colab_type": "text"
      },
      "source": [
        "Now, let's run inference with the trained model on the balloon validation dataset. First, let's create a predictor using the model we just trained:\n",
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YF3XvR46ZqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(gdrive_dir, 'model_final.pth')\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = ('coin_val', )\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_coin_dicts(gdrive_dir + 'val')\n",
        "for d in random.sample(dataset_dicts, 3):    \n",
        "    im = cv2.imread(d['file_name'])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=coin_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs['instances'].to('cpu'))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoCByAU5fl2W",
        "colab_type": "text"
      },
      "source": [
        "# Validate model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sSnhOlO4mLC",
        "colab_type": "text"
      },
      "source": [
        "Import pretrained model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYfOhMNC2TT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = get_cfg()\n",
        "config.merge_from_file(model_zoo.get_config_file('COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml'))\n",
        "config.MODEL.WEIGHTS = os.path.join(gdrive_dir, 'model_final.pth')\n",
        "config.DATALOADER.NUM_WORKERS = 2\n",
        "config.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "config.SOLVER.IMS_PER_BATCH = 2\n",
        "config.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (coin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_b88prx4xEw",
        "colab_type": "text"
      },
      "source": [
        "Check predictions on unannotated data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9jgXMtn40mI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor_new = DefaultPredictor(config)\n",
        "\n",
        "img_dir = os.path.join(gdrive_dir, 'predict')\n",
        "for file in os.listdir(img_dir):\n",
        "  if not file.endswith('.jpg'):\n",
        "    continue\n",
        "  im = cv2.imread(os.path.join(img_dir, file))\n",
        "  output = predictor_new(im)\n",
        "  v = Visualizer(im[:, :, ::-1], coin_metadata, scale=1.2)\n",
        "  v = v.draw_instance_predictions(output[\"instances\"].to(\"cpu\"))\n",
        "  cv2_imshow(v.get_image()[:, :, ::-1])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}